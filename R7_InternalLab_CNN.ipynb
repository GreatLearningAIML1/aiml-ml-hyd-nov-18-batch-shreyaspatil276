{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"R7_InternalLab_CNN.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"MyfMmMnPJjvn"},"source":["## Train a simple convnet on the Fashion MNIST dataset"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"zjcGOJhcJjvp"},"source":["In this, we will see how to deal with image data and train a convnet for image classification task."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jR0Pl2XjJjvq"},"source":["### Load the  `fashion_mnist`  dataset\n","\n","** Use keras.datasets to load the dataset **"]},{"cell_type":"code","metadata":{"id":"gYN0jS76aIAO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"9d035b81-1bc5-4a42-c863-26660e3970de","executionInfo":{"status":"ok","timestamp":1560074338128,"user_tz":-330,"elapsed":2366,"user":{"displayName":"Shreyas Patil","photoUrl":"https://lh5.googleusercontent.com/-4xT-vdHMCi4/AAAAAAAAAAI/AAAAAAAABIw/229AdDukwuQ/s64/photo.jpg","userId":"05525686908634550541"}}},"source":["import keras\n","import tensorflow as tf\n","tf.reset_default_graph()\n","tf.set_random_seed(1)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Qr75v_UYJjvs","outputId":"1ebde4fc-a60b-465d-c84e-f0b22b70af57","executionInfo":{"status":"ok","timestamp":1560074345084,"user_tz":-330,"elapsed":6000,"user":{"displayName":"Shreyas Patil","photoUrl":"https://lh5.googleusercontent.com/-4xT-vdHMCi4/AAAAAAAAAAI/AAAAAAAABIw/229AdDukwuQ/s64/photo.jpg","userId":"05525686908634550541"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["from keras.datasets import fashion_mnist\n","(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n","32768/29515 [=================================] - 0s 4us/step\n","Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n","26427392/26421880 [==============================] - 2s 0us/step\n","Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n","8192/5148 [===============================================] - 0s 0us/step\n","Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n","4423680/4422102 [==============================] - 1s 0us/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hTI42-0qJjvw"},"source":["### Find no.of samples are there in training and test datasets"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"g2sf67VoJjvx","outputId":"7697fd10-249e-494b-90d4-ab2f2be65f52","executionInfo":{"status":"ok","timestamp":1560074345093,"user_tz":-330,"elapsed":3051,"user":{"displayName":"Shreyas Patil","photoUrl":"https://lh5.googleusercontent.com/-4xT-vdHMCi4/AAAAAAAAAAI/AAAAAAAABIw/229AdDukwuQ/s64/photo.jpg","userId":"05525686908634550541"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["x_train.shape"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60000, 28, 28)"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zewyDcBlJjv1","outputId":"a4bf202c-6014-4f44-ad12-0c45aeb4b97e","executionInfo":{"status":"ok","timestamp":1560074345097,"user_tz":-330,"elapsed":1796,"user":{"displayName":"Shreyas Patil","photoUrl":"https://lh5.googleusercontent.com/-4xT-vdHMCi4/AAAAAAAAAAI/AAAAAAAABIw/229AdDukwuQ/s64/photo.jpg","userId":"05525686908634550541"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["x_test.shape"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000, 28, 28)"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WytT2eRnJjv4"},"source":["### Find dimensions of an image in the dataset"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"XycQGBSGJjv5","outputId":"38cc287c-1321-4534-ceb5-49e20ebcfb55","executionInfo":{"status":"ok","timestamp":1560074345430,"user_tz":-330,"elapsed":616,"user":{"displayName":"Shreyas Patil","photoUrl":"https://lh5.googleusercontent.com/-4xT-vdHMCi4/AAAAAAAAAAI/AAAAAAAABIw/229AdDukwuQ/s64/photo.jpg","userId":"05525686908634550541"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["x_train[0].shape"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(28, 28)"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"Oq1L2j71b34o","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"1b9a3c42-17ca-45e3-d538-74cd6020f34a","executionInfo":{"status":"ok","timestamp":1560074346577,"user_tz":-330,"elapsed":1028,"user":{"displayName":"Shreyas Patil","photoUrl":"https://lh5.googleusercontent.com/-4xT-vdHMCi4/AAAAAAAAAAI/AAAAAAAABIw/229AdDukwuQ/s64/photo.jpg","userId":"05525686908634550541"}}},"source":["import numpy as np\n","np.bincount(y_train).shape"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10,)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"5jtdZ7RqJjv8"},"source":["### Convert train and test labels to one hot vectors\n","\n","** check `keras.utils.to_categorical()` **"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"sAD3q5I6Jjv9","colab":{}},"source":["trainY=keras.utils.to_categorical(y_train,num_classes=10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"1eb18800-6eb4-416c-e9d5-382ae8b598a8","executionInfo":{"status":"ok","timestamp":1560074349004,"user_tz":-330,"elapsed":599,"user":{"displayName":"Shreyas Patil","photoUrl":"https://lh5.googleusercontent.com/-4xT-vdHMCi4/AAAAAAAAAAI/AAAAAAAABIw/229AdDukwuQ/s64/photo.jpg","userId":"05525686908634550541"}},"id":"GlXg1TjLdUpo","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["trainY.shape"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60000, 10)"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"Yh8ynSqHdVGa","colab_type":"code","colab":{}},"source":["testY=keras.utils.to_categorical(y_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Peoc9DO6dfK6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"36eef195-ad76-4735-817e-1678565087f2","executionInfo":{"status":"ok","timestamp":1560074350513,"user_tz":-330,"elapsed":602,"user":{"displayName":"Shreyas Patil","photoUrl":"https://lh5.googleusercontent.com/-4xT-vdHMCi4/AAAAAAAAAAI/AAAAAAAABIw/229AdDukwuQ/s64/photo.jpg","userId":"05525686908634550541"}}},"source":["testY.shape"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000, 10)"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xO5BRBzBJjwD"},"source":["### Normalize both the train and test image data from 0-255 to 0-1"]},{"cell_type":"code","metadata":{"id":"GGdANmqqdOPD","colab_type":"code","colab":{}},"source":["x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')\n","x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')\n","x_train /= 255\n","x_test /= 255"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"da5-DwgrJjwM"},"source":["### Reshape the data from 28x28 to 28x28x1 to match input dimensions in Conv2D layer in keras"]},{"cell_type":"markdown","metadata":{"id":"T-JyelD-lPvl","colab_type":"text"},"source":["Done Reshaping in previous step."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"OFRRTJq8JjwQ"},"source":["### Import the necessary layers from keras to build the model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dWTZYnKSJjwR","colab":{}},"source":["from keras.layers import Dense, Activation, Dropout, Flatten, Reshape\n","from keras.layers import Convolution2D, MaxPooling2D\n","from keras.models import Sequential"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"C18AoS7eJjwU"},"source":["### Build a model \n","\n","** with 2 Conv layers having `32 3*3 filters` in both convolutions with `relu activations` and `flatten` before passing the feature map into 2 fully connected layers (or Dense Layers) having 128 and 10 neurons with `relu` and `softmax` activations respectively. Now, using `categorical_crossentropy` loss with `adam` optimizer train the model with early stopping `patience=5` and no.of `epochs=10`. **"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DORCLgSwJjwV","colab":{}},"source":["TRAIN = False\n","BATCH_SIZE = 32\n","EPOCHS = 10"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KQBCkZwVlpXj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":615},"outputId":"8f256a10-7e62-4642-a135-e2268bea8473","executionInfo":{"status":"ok","timestamp":1560074467455,"user_tz":-330,"elapsed":106973,"user":{"displayName":"Shreyas Patil","photoUrl":"https://lh5.googleusercontent.com/-4xT-vdHMCi4/AAAAAAAAAAI/AAAAAAAABIw/229AdDukwuQ/s64/photo.jpg","userId":"05525686908634550541"}}},"source":["  # Define model\n","    model2 = Sequential()\n","\n","    # 1st Conv Layer\n","    model2.add(Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n","    model2.add(Activation('relu'))\n","\n","    # 2nd Conv Layer\n","    model2.add(Convolution2D(32, 3, 3))\n","    model2.add(Activation('relu'))\n","\n","    # Fully Connected Layer\n","    model2.add(Flatten())\n","    model2.add(Dense(128))\n","    model2.add(Activation('relu'))\n","\n","    # Prediction Layer\n","    model2.add(Dense(10))\n","    model2.add(Activation('softmax'))\n","\n","    # Loss and Optimizer\n","    model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    \n","    # Store Training Results\n","    early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='auto')\n","    callback_list = [early_stopping]\n","\n","    # Train the model2\n","    model2.fit(x_train, trainY, batch_size=BATCH_SIZE, nb_epoch=EPOCHS, \n","              validation_data=(x_test, testY), callbacks=callback_list)\n","    \n"],"execution_count":14,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1...)`\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n","  \n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/10\n","60000/60000 [==============================] - 16s 271us/step - loss: 0.3717 - acc: 0.8648 - val_loss: 0.2891 - val_acc: 0.8959\n","Epoch 2/10\n","60000/60000 [==============================] - 10s 165us/step - loss: 0.2279 - acc: 0.9161 - val_loss: 0.2475 - val_acc: 0.9107\n","Epoch 3/10\n","60000/60000 [==============================] - 10s 165us/step - loss: 0.1651 - acc: 0.9384 - val_loss: 0.2448 - val_acc: 0.9135\n","Epoch 4/10\n","60000/60000 [==============================] - 10s 165us/step - loss: 0.1142 - acc: 0.9571 - val_loss: 0.2807 - val_acc: 0.9130\n","Epoch 5/10\n","60000/60000 [==============================] - 10s 166us/step - loss: 0.0755 - acc: 0.9722 - val_loss: 0.2947 - val_acc: 0.9179\n","Epoch 6/10\n","60000/60000 [==============================] - 10s 166us/step - loss: 0.0510 - acc: 0.9812 - val_loss: 0.3614 - val_acc: 0.9134\n","Epoch 7/10\n","60000/60000 [==============================] - 10s 166us/step - loss: 0.0369 - acc: 0.9864 - val_loss: 0.3961 - val_acc: 0.9102\n","Epoch 8/10\n","60000/60000 [==============================] - 10s 166us/step - loss: 0.0287 - acc: 0.9899 - val_loss: 0.4064 - val_acc: 0.9165\n","Epoch 9/10\n","60000/60000 [==============================] - 10s 167us/step - loss: 0.0240 - acc: 0.9911 - val_loss: 0.4744 - val_acc: 0.9077\n","Epoch 10/10\n","60000/60000 [==============================] - 10s 165us/step - loss: 0.0187 - acc: 0.9938 - val_loss: 0.4675 - val_acc: 0.9090\n","Epoch 00010: early stopping\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f201298a7f0>"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ju69vKdIJjwX"},"source":["### Now, to the above model add `max` pooling layer of `filter size 2x2` and `dropout` layer with `p=0.25` after the 2 conv layers and run the model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"L2hAP94vJjwY","colab":{"base_uri":"https://localhost:8080/","height":547},"outputId":"0612aa09-4f28-430c-d025-6edb2c8b4854","executionInfo":{"status":"ok","timestamp":1560074582467,"user_tz":-330,"elapsed":83843,"user":{"displayName":"Shreyas Patil","photoUrl":"https://lh5.googleusercontent.com/-4xT-vdHMCi4/AAAAAAAAAAI/AAAAAAAABIw/229AdDukwuQ/s64/photo.jpg","userId":"05525686908634550541"}}},"source":["\n","    # Define Model\n","    model3 = Sequential()\n","\n","    # 1st Conv Layer\n","    model3.add(Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n","    model3.add(Activation('relu'))\n","\n","    # 2nd Conv Layer\n","    model3.add(Convolution2D(32, 3, 3))\n","    model3.add(Activation('relu'))\n","\n","    # Max Pooling\n","    model3.add(MaxPooling2D(pool_size=(2,2)))\n","    \n","    # Dropout\n","    model3.add(Dropout(0.25))\n","\n","    # Fully Connected Layer\n","    model3.add(Flatten())\n","    model3.add(Dense(128))\n","    model3.add(Activation('relu'))\n","    \n","    # More Dropout\n","    model3.add(Dropout(0.5))\n","\n","    # Prediction Layer\n","    model3.add(Dense(10))\n","    model3.add(Activation('softmax'))\n","\n","    # Loss and Optimizer\n","    model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    \n","    # Store Training Results\n","    early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='auto')\n","    callback_list = [early_stopping]\n","\n","    # Train the model\n","    model3.fit(x_train, trainY, batch_size=BATCH_SIZE, nb_epoch=EPOCHS, \n","              validation_data=(x_test, testY), callbacks=callback_list)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1...)`\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n","  \n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/10\n","60000/60000 [==============================] - 9s 147us/step - loss: 0.4743 - acc: 0.8297 - val_loss: 0.3153 - val_acc: 0.8866\n","Epoch 2/10\n","60000/60000 [==============================] - 8s 136us/step - loss: 0.3213 - acc: 0.8839 - val_loss: 0.2652 - val_acc: 0.9033\n","Epoch 3/10\n","60000/60000 [==============================] - 8s 136us/step - loss: 0.2772 - acc: 0.8984 - val_loss: 0.2573 - val_acc: 0.9041\n","Epoch 4/10\n","60000/60000 [==============================] - 8s 136us/step - loss: 0.2518 - acc: 0.9075 - val_loss: 0.2411 - val_acc: 0.9104\n","Epoch 5/10\n","60000/60000 [==============================] - 8s 135us/step - loss: 0.2294 - acc: 0.9154 - val_loss: 0.2283 - val_acc: 0.9158\n","Epoch 6/10\n","60000/60000 [==============================] - 8s 136us/step - loss: 0.2110 - acc: 0.9206 - val_loss: 0.2379 - val_acc: 0.9155\n","Epoch 7/10\n","60000/60000 [==============================] - 8s 134us/step - loss: 0.2010 - acc: 0.9263 - val_loss: 0.2223 - val_acc: 0.9221\n","Epoch 8/10\n","60000/60000 [==============================] - 8s 138us/step - loss: 0.1885 - acc: 0.9312 - val_loss: 0.2142 - val_acc: 0.9261\n","Epoch 9/10\n","60000/60000 [==============================] - 8s 140us/step - loss: 0.1764 - acc: 0.9341 - val_loss: 0.2177 - val_acc: 0.9251\n","Epoch 10/10\n","60000/60000 [==============================] - 8s 137us/step - loss: 0.1697 - acc: 0.9360 - val_loss: 0.2193 - val_acc: 0.9228\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f200643a2e8>"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"lGTA3bfEJjwa"},"source":["### Now, to the above model, lets add Data Augmentation "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"F6gX8n5SJjwb"},"source":["### Import the ImageDataGenrator from keras and fit the training images"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Cbz4uHBuJjwc","colab":{}},"source":["from keras.preprocessing.image import ImageDataGenerator\n","\n","# This will do preprocessing and realtime data augmentation:\n","datagen = ImageDataGenerator(\n","    featurewise_center=False,  # set input mean to 0 over the dataset\n","    samplewise_center=False,  # set each sample mean to 0\n","    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","    samplewise_std_normalization=False,  # divide each input by its std\n","    zca_whitening=False,  # apply ZCA whitening\n","    rotation_range=50,  # randomly rotate images in the range (degrees, 0 to 180)\n","    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n","    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n","    horizontal_flip=False,  # randomly flip images\n","    vertical_flip=False)  # randomly flip images\n","\n","# Prepare the generator\n","datagen.fit(x_train)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pl-8dOo7Jjwf"},"source":["#### Showing 5 versions of the first image in training dataset using image datagenerator.flow()"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DpI1_McYJjwg","outputId":"05089ffa-00c8-4703-f9d3-b6428c6b125c","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":109},"executionInfo":{"status":"ok","timestamp":1560075354645,"user_tz":-330,"elapsed":910,"user":{"displayName":"Shreyas Patil","photoUrl":"https://lh5.googleusercontent.com/-4xT-vdHMCi4/AAAAAAAAAAI/AAAAAAAABIw/229AdDukwuQ/s64/photo.jpg","userId":"05525686908634550541"}}},"source":["from matplotlib import pyplot as plt\n","gen = datagen.flow(x_train[0:1], batch_size=1)\n","for i in range(1, 6):\n","    plt.subplot(1,5,i)\n","    plt.axis(\"off\")\n","    plt.imshow(gen.next().squeeze(), cmap='gray')\n","    plt.plot()\n","plt.show()"],"execution_count":17,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXIAAABcCAYAAABz9T77AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 5 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"dmPl5yE8Jjwm"},"source":["### Run the above model using fit_generator()"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"44ZnDdJYJjwn","colab":{"base_uri":"https://localhost:8080/","height":496},"outputId":"1f9e5b38-a33e-4f55-bb16-6c2902954202","executionInfo":{"status":"ok","timestamp":1560076076087,"user_tz":-330,"elapsed":183127,"user":{"displayName":"Shreyas Patil","photoUrl":"https://lh5.googleusercontent.com/-4xT-vdHMCi4/AAAAAAAAAAI/AAAAAAAABIw/229AdDukwuQ/s64/photo.jpg","userId":"05525686908634550541"}}},"source":[" # Define Model\n","    model4 = Sequential()\n","\n","    # 1st Conv Layer\n","    model4.add(Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n","    model4.add(Activation('relu'))\n","\n","    # 2nd Conv Layer\n","    model4.add(Convolution2D(32, 3, 3))\n","    model4.add(Activation('relu'))\n","\n","    # Max Pooling\n","    model4.add(MaxPooling2D(pool_size=(2,2)))\n","    \n","    # Dropout\n","    model4.add(Dropout(0.25))\n","\n","    # Fully Connected Layer\n","    model4.add(Flatten())\n","    model4.add(Dense(128))\n","    model4.add(Activation('relu'))\n","    \n","    # More Dropout\n","    model4.add(Dropout(0.5))\n","\n","    # Prediction Layer\n","    model4.add(Dense(10))\n","    model4.add(Activation('softmax'))\n","\n","    # Loss and Optimizer\n","    model4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    \n","    # Store Training Results\n","    early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='auto')\n","    callback_list = [early_stopping]\n","\n","    # Train the model\n","    model4.fit_generator(datagen.flow(x_train, trainY, batch_size=BATCH_SIZE), nb_epoch=EPOCHS,samples_per_epoch=x_train.shape[0], \n","              validation_data=(x_test, testY), callbacks=callback_list)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1...)`\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n","  \n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., callbacks=[<keras.ca..., steps_per_epoch=1875, epochs=10)`\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/10\n","1875/1875 [==============================] - 19s 10ms/step - loss: 0.9583 - acc: 0.6480 - val_loss: 0.5972 - val_acc: 0.7717\n","Epoch 2/10\n","1875/1875 [==============================] - 18s 10ms/step - loss: 0.7233 - acc: 0.7286 - val_loss: 0.5473 - val_acc: 0.7963\n","Epoch 3/10\n","1875/1875 [==============================] - 18s 10ms/step - loss: 0.6601 - acc: 0.7539 - val_loss: 0.5287 - val_acc: 0.8008\n","Epoch 4/10\n","1875/1875 [==============================] - 18s 10ms/step - loss: 0.6270 - acc: 0.7666 - val_loss: 0.4860 - val_acc: 0.8204\n","Epoch 5/10\n","1875/1875 [==============================] - 18s 10ms/step - loss: 0.6044 - acc: 0.7761 - val_loss: 0.4677 - val_acc: 0.8260\n","Epoch 6/10\n","1875/1875 [==============================] - 18s 10ms/step - loss: 0.5813 - acc: 0.7844 - val_loss: 0.4379 - val_acc: 0.8418\n","Epoch 7/10\n","1875/1875 [==============================] - 18s 10ms/step - loss: 0.5647 - acc: 0.7930 - val_loss: 0.4195 - val_acc: 0.8488\n","Epoch 8/10\n","1875/1875 [==============================] - 18s 10ms/step - loss: 0.5477 - acc: 0.7993 - val_loss: 0.4310 - val_acc: 0.8423\n","Epoch 9/10\n","1875/1875 [==============================] - 18s 10ms/step - loss: 0.5364 - acc: 0.8021 - val_loss: 0.4274 - val_acc: 0.8508\n","Epoch 10/10\n","1875/1875 [==============================] - 18s 10ms/step - loss: 0.5266 - acc: 0.8060 - val_loss: 0.4419 - val_acc: 0.8431\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f1fe5355a58>"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"MwQQW5iOJjwq"},"source":["###  Report the final train and validation accuracy"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"c1SrtBEPJjwq","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"3b158e53-2bd4-473b-aed9-4f8768451de0","executionInfo":{"status":"ok","timestamp":1560076556592,"user_tz":-330,"elapsed":1333,"user":{"displayName":"Shreyas Patil","photoUrl":"https://lh5.googleusercontent.com/-4xT-vdHMCi4/AAAAAAAAAAI/AAAAAAAABIw/229AdDukwuQ/s64/photo.jpg","userId":"05525686908634550541"}}},"source":["model4.evaluate(x_test,testY)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["10000/10000 [==============================] - 1s 57us/step\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.4418986359357834, 0.8431]"]},"metadata":{"tags":[]},"execution_count":24}]}]}