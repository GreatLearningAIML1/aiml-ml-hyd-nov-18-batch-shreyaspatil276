{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sb7Epo0VOB58"
   },
   "source": [
    "### Load tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fHpCNRv1OB5-"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tnSsH8sNOB6F",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Reset Default graph - Needed only for Jupyter notebook\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DxJDmJqqOB6K",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FhllFLyKOB6N"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B4yQKMiJOB6R"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('prices.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fgkX6SEqOB6W"
   },
   "source": [
    "### Check all columns in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7K8pWsNQOB6X"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(851264, 7)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'symbol', 'open', 'close', 'low', 'high', 'volume'], dtype='object')"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7dU6X7MpOB6c"
   },
   "source": [
    "### Drop columns `date` and  `symbol`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lh_6spSKOB6e"
   },
   "outputs": [],
   "source": [
    "data.drop(['date','symbol'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xlwbUgTwOB6i",
    "outputId": "56bad82a-f271-415a-e0d6-cbe1c4290743"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123.430000</td>\n",
       "      <td>125.839996</td>\n",
       "      <td>122.309998</td>\n",
       "      <td>126.250000</td>\n",
       "      <td>2163600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125.239998</td>\n",
       "      <td>119.980003</td>\n",
       "      <td>119.940002</td>\n",
       "      <td>125.540001</td>\n",
       "      <td>2386400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.379997</td>\n",
       "      <td>114.949997</td>\n",
       "      <td>114.930000</td>\n",
       "      <td>119.739998</td>\n",
       "      <td>2489500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115.480003</td>\n",
       "      <td>116.620003</td>\n",
       "      <td>113.500000</td>\n",
       "      <td>117.440002</td>\n",
       "      <td>2006300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>117.010002</td>\n",
       "      <td>114.970001</td>\n",
       "      <td>114.089996</td>\n",
       "      <td>117.330002</td>\n",
       "      <td>1408600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         open       close         low        high     volume\n",
       "0  123.430000  125.839996  122.309998  126.250000  2163600.0\n",
       "1  125.239998  119.980003  119.940002  125.540001  2386400.0\n",
       "2  116.379997  114.949997  114.930000  119.739998  2489500.0\n",
       "3  115.480003  116.620003  113.500000  117.440002  2006300.0\n",
       "4  117.010002  114.970001  114.089996  117.330002  1408600.0"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3DBv3WWYOB6q"
   },
   "source": [
    "### Consider only first 1000 rows in the dataset for building feature set and target set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z_hG9rGBOB6s"
   },
   "outputs": [],
   "source": [
    "X=data.loc[:999,['open','low','high','volume']]\n",
    "Y=data.loc[:999,['close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 4)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M3UaApqYOB6x"
   },
   "source": [
    "### Divide the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2EkKAy7fOB6y"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v6vE4eYCOB62",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building the graph in tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xK0zBd1VOB64",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1.Define input data placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JDrYlWTuOB66"
   },
   "outputs": [],
   "source": [
    "#Input features\n",
    "x = tf.placeholder(shape=[None,4],dtype=tf.float32, name='x-input')\n",
    "\n",
    "#Normalize the data\n",
    "x_n = tf.nn.l2_normalize(x,1)\n",
    "\n",
    "#Actual Prices\n",
    "y_ = tf.placeholder(shape=[None,1],dtype=tf.float32, name='y-input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "297_qja4OB7A",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2.Define Weights and Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L205qPeQOB7B"
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros(shape=[4,1]), name=\"Weights\")\n",
    "b = tf.Variable(tf.zeros(shape=[1]),name=\"Bias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HgtWA-UIOB7F",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "3.Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JveGlx25OB7H"
   },
   "outputs": [],
   "source": [
    "y_pred = tf.add(tf.matmul(x_n,W),b,name='output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TL1hIwf_OB7M",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "4.Loss (Cost) Function [Mean square error]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8VSWPiGXOB7P"
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(y_pred-y_),name='Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jzG85FUlOB7U",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "5.GradientDescent Optimizer to minimize Loss [GradientDescentOptimizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cj802w-3OB7X"
   },
   "outputs": [],
   "source": [
    "train_op = tf.train.GradientDescentOptimizer(0.03).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xSypb_u8OB7e",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Execute the Graph for 100 epochs and observe the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DVvgj7eQOB7f"
   },
   "outputs": [],
   "source": [
    "#start graph Execution\n",
    "sess = tf.Session()\n",
    "\n",
    "# variables need to be initialized before we can use them\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#how many times data need to be shown to model\n",
    "training_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9smwOW-1OB7k"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at step:  0  is  7817.284\n",
      "Training loss at step:  10  is  3684.1895\n",
      "Training loss at step:  20  is  3363.6152\n",
      "Training loss at step:  30  is  3338.7507\n",
      "Training loss at step:  40  is  3336.8218\n",
      "Training loss at step:  50  is  3336.6726\n",
      "Training loss at step:  60  is  3336.6606\n",
      "Training loss at step:  70  is  3336.6597\n",
      "Training loss at step:  80  is  3336.6594\n",
      "Training loss at step:  90  is  3336.66\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "            \n",
    "    #Calculate train_op and loss\n",
    "    _, train_loss = sess.run([train_op,loss],feed_dict={x:X_train, y_:Y_train})\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print ('Training loss at step: ', epoch, ' is ', train_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DOL2ncA1OB7q"
   },
   "source": [
    "### Get the shapes and values of W and b\n",
    "\n",
    "Hint: Use sess.run(W) to get W."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZGvtyTeuOB7r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.3045467e-02],\n",
       "       [2.2827424e-02],\n",
       "       [2.3217712e-02],\n",
       "       [3.3468628e+01]], dtype=float32)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(W.shape)\n",
    "sess.run(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vhDtOv5UOB7x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([33.46864], dtype=float32)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(b.shape)\n",
    "sess.run(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SZqKUEFsOB71"
   },
   "source": [
    "### Find the Absolute mean square loss difference between training and testing loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "97t-grQgOB71"
   },
   "outputs": [],
   "source": [
    "test_loss = sess.run(tf.reduce_sum(loss),feed_dict={x:X_test, y_:Y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KjOInjUROB75"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "329.46802"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_mse_loss=abs(train_loss-test_loss)\n",
    "abs_mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YJRBuqXhOB7_"
   },
   "source": [
    "### Linear Classification using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GoNTWXAOB8C",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Building the simple Neural Network in Keras with one neuron in the dense hidden layer.\n",
    "#### Use Mean square error as loss function and sgd as optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zpeL5rCTOB8D",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Initialize Sequential Graph (model)\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#Normalize input data\n",
    "model.add(tf.keras.layers.Dense(1,input_shape=(4,)))\n",
    "\n",
    "#Add Dense layer for prediction \n",
    "model.add(tf.keras.layers.Dense(1,activation='softmax'))\n",
    "\n",
    "#Compile the model - add Loss and Gradient Descent optimizer\n",
    "model.compile(optimizer='sgd', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wt-HYFMEOB8G",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Execute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "66JGJt7GOB8H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "800/800 [==============================] - 0s 474us/sample - loss: 8246.4213\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 8246.4211\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 8246.4211\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 8246.4211\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 8246.4213\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 8246.4211\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 8246.4210\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 8246.4212\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 8246.4212\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 8246.4213\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 8246.4212\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 8246.4211\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 8246.4211\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 8246.4212\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 0s 75us/sample - loss: 8246.4210\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 8246.4211\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 8246.4211\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 8246.4211\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 8246.4212\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 8246.4212\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 8246.4211\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 8246.4212\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 8246.4212\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 8246.4212\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 8246.4212\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 0s 76us/sample - loss: 8246.4212\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 8246.4212\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 0s 76us/sample - loss: 8246.4210\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 0s 75us/sample - loss: 8246.4213\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 8246.4211\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 8246.4210\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 0s 75us/sample - loss: 8246.4211\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 8246.4211\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 0s 78us/sample - loss: 8246.4213\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 8246.4212\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 8246.4213\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 0s 74us/sample - loss: 8246.4211\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 0s 76us/sample - loss: 8246.4211\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 8246.4211\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 0s 74us/sample - loss: 8246.4211\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 0s 78us/sample - loss: 8246.4211\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 8246.4212\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 8246.4210\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 0s 74us/sample - loss: 8246.4210\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 8246.4210\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 8246.4211\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 8246.4211\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 0s 75us/sample - loss: 8246.4213\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 8246.4209\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 8246.4212\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 8246.4211\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 8246.4212\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 8246.4211\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 8246.4213\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 8246.4210\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 8246.4213\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 8246.4212\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 8246.4211\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 8246.4213\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 8246.4211\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 8246.4211\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 8246.4212\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 8246.4211\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 0s 78us/sample - loss: 8246.4212\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 8246.4211\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 0s 74us/sample - loss: 8246.4212\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 8246.4212\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 8246.4212\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 8246.4211\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 0s 83us/sample - loss: 8246.4210\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 0s 76us/sample - loss: 8246.4212\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 0s 75us/sample - loss: 8246.4213\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 8246.4210\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 8246.4210\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 8246.4209\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 8246.4211\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 8246.4211\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 8246.4211\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 8246.4211\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 8246.4212\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 8246.4211\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 8246.4211\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 8246.4211\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 8246.4211\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 8246.4212\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 8246.4212\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 8246.4211\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 8246.4212\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 8246.4212\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 8246.4212\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 8246.4211\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 8246.4211\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 59us/sample - loss: 8246.4213\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 8246.4211\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 8246.4211\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 8246.4212\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 8246.4211\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 8246.4211\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 8246.4211\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 8246.4212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xd8456694e0>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification using Keras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the given Iris data using pandas (Iris.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data=pd.read_csv('iris.csv')\n",
    "iris_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into feature set and target set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=iris_data.loc[:,['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']]\n",
    "target=iris_data.loc[:,['Species']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target set has different categories. So, Label encode them. And convert into one-hot vectors using get_dummies in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreyaspatil\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "Le=LabelEncoder()\n",
    "label=Le.fit_transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2\n",
       "0  1  0  0\n",
       "1  1  0  0\n",
       "2  1  0  0\n",
       "3  1  0  0\n",
       "4  1  0  0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target=pd.DataFrame(pd.get_dummies(label))\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide the dataset into Training and test (70:30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train,X1_test,Y1_train,Y1_test=train_test_split(features,target,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "Build the model with following layers: <br>\n",
    "1. First dense layer with 10 neurons with input shape 4 (according to the feature set) <br>\n",
    "2. Second Dense layer with 8 neurons <br>\n",
    "3. Output layer with 3 neurons with softmax activation (output layer, 3 neurons as we have 3 classes) <br>\n",
    "4. Use SGD and categorical_crossentropy loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Sequential Graph (model)\n",
    "model1 = tf.keras.models.Sequential()\n",
    "\n",
    "#Normalize input data\n",
    "model1.add(tf.keras.layers.Dense(10,input_shape=(4,)))\n",
    "\n",
    "model1.add(tf.keras.layers.Dense(8,activation='relu'))\n",
    "#Add Dense layer for prediction \n",
    "model1.add(tf.keras.layers.Dense(3,activation='softmax'))\n",
    "\n",
    "model1.compile(optimizer='sgd', loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the model and predicting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.1700 - acc: 0.9714\n",
      "Epoch 2/50\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.1706 - acc: 0.9714\n",
      "Epoch 3/50\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.1671 - acc: 0.9714\n",
      "Epoch 4/50\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.1714 - acc: 0.9810\n",
      "Epoch 5/50\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.1676 - acc: 0.9810\n",
      "Epoch 6/50\n",
      "105/105 [==============================] - 0s 105us/sample - loss: 0.2089 - acc: 0.9429\n",
      "Epoch 7/50\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.1636 - acc: 0.9714\n",
      "Epoch 8/50\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.1635 - acc: 0.9619\n",
      "Epoch 9/50\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.1572 - acc: 0.9810\n",
      "Epoch 10/50\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.1682 - acc: 0.9714\n",
      "Epoch 11/50\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.1905 - acc: 0.9333\n",
      "Epoch 12/50\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.1641 - acc: 0.9524\n",
      "Epoch 13/50\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.1621 - acc: 0.9524\n",
      "Epoch 14/50\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.1659 - acc: 0.9429\n",
      "Epoch 15/50\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.1580 - acc: 0.9714\n",
      "Epoch 16/50\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.1603 - acc: 0.9524\n",
      "Epoch 17/50\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.1532 - acc: 0.9524\n",
      "Epoch 18/50\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.1726 - acc: 0.9429\n",
      "Epoch 19/50\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.1616 - acc: 0.9524\n",
      "Epoch 20/50\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.1930 - acc: 0.9333\n",
      "Epoch 21/50\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.1436 - acc: 0.9714\n",
      "Epoch 22/50\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.1485 - acc: 0.9619\n",
      "Epoch 23/50\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.1550 - acc: 0.9524\n",
      "Epoch 24/50\n",
      "105/105 [==============================] - 0s 105us/sample - loss: 0.1537 - acc: 0.9429\n",
      "Epoch 25/50\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.1543 - acc: 0.9429\n",
      "Epoch 26/50\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.1392 - acc: 0.9619\n",
      "Epoch 27/50\n",
      "105/105 [==============================] - 0s 162us/sample - loss: 0.1606 - acc: 0.9524\n",
      "Epoch 28/50\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.1592 - acc: 0.9238\n",
      "Epoch 29/50\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.1714 - acc: 0.9429\n",
      "Epoch 30/50\n",
      "105/105 [==============================] - 0s 162us/sample - loss: 0.1387 - acc: 0.9714\n",
      "Epoch 31/50\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.1357 - acc: 0.9619\n",
      "Epoch 32/50\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.1415 - acc: 0.9524\n",
      "Epoch 33/50\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.1510 - acc: 0.9619\n",
      "Epoch 34/50\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.1543 - acc: 0.9524\n",
      "Epoch 35/50\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.1335 - acc: 0.9524\n",
      "Epoch 36/50\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.1329 - acc: 0.9524\n",
      "Epoch 37/50\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.1286 - acc: 0.9714\n",
      "Epoch 38/50\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.1293 - acc: 0.9619\n",
      "Epoch 39/50\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.1332 - acc: 0.9619\n",
      "Epoch 40/50\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.1566 - acc: 0.9524\n",
      "Epoch 41/50\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.1370 - acc: 0.9619\n",
      "Epoch 42/50\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.1345 - acc: 0.9429\n",
      "Epoch 43/50\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.1245 - acc: 0.9714\n",
      "Epoch 44/50\n",
      "105/105 [==============================] - 0s 181us/sample - loss: 0.1416 - acc: 0.9619\n",
      "Epoch 45/50\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.1315 - acc: 0.9429\n",
      "Epoch 46/50\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.1482 - acc: 0.9429\n",
      "Epoch 47/50\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.1209 - acc: 0.9714\n",
      "Epoch 48/50\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.1222 - acc: 0.9714\n",
      "Epoch 49/50\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.1412 - acc: 0.9333\n",
      "Epoch 50/50\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.1260 - acc: 0.9524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xd84814d3c8>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X1_train, Y1_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 133us/sample - loss: 0.1333 - acc: 0.9778\n"
     ]
    }
   ],
   "source": [
    "score=model1.evaluate(X1_test,Y1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report Accuracy of the predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 97.77777791023254\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy =\",score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted=model1.predict(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.97418875e-05, 1.72722742e-01, 8.27217519e-01],\n",
       "       [7.67400162e-03, 8.77839863e-01, 1.14486188e-01],\n",
       "       [3.35538480e-03, 7.69436479e-01, 2.27208197e-01],\n",
       "       [1.03762476e-02, 8.99338424e-01, 9.02852714e-02],\n",
       "       [9.79797304e-01, 2.02026647e-02, 5.13293728e-08],\n",
       "       [3.58077581e-03, 8.48313987e-01, 1.48105249e-01],\n",
       "       [5.17400913e-05, 1.57287538e-01, 8.42660666e-01],\n",
       "       [5.71487035e-05, 1.47726059e-01, 8.52216840e-01],\n",
       "       [9.92430389e-01, 7.56964693e-03, 2.17108331e-09],\n",
       "       [1.72814354e-02, 9.29514825e-01, 5.32038100e-02],\n",
       "       [1.26487180e-03, 5.29916584e-01, 4.68818575e-01],\n",
       "       [1.48223713e-04, 2.13072225e-01, 7.86779523e-01],\n",
       "       [9.86561477e-01, 1.34384921e-02, 2.89239530e-08],\n",
       "       [4.35698126e-03, 9.21793044e-01, 7.38500059e-02],\n",
       "       [9.80371296e-01, 1.96286123e-02, 5.87637281e-08],\n",
       "       [9.95741487e-01, 4.25854651e-03, 1.03339204e-09],\n",
       "       [6.98447329e-05, 2.75252402e-01, 7.24677742e-01],\n",
       "       [5.50697405e-06, 4.55795527e-02, 9.54414964e-01],\n",
       "       [2.20044626e-06, 2.46806275e-02, 9.75317121e-01],\n",
       "       [9.90613818e-01, 9.38614551e-03, 4.92165908e-09],\n",
       "       [9.71140504e-01, 2.88593955e-02, 8.61171046e-08],\n",
       "       [9.74720478e-01, 2.52795629e-02, 4.09112744e-08],\n",
       "       [6.27743793e-06, 6.16251901e-02, 9.38368499e-01],\n",
       "       [9.92253363e-01, 7.74668064e-03, 2.62671263e-09],\n",
       "       [3.79909724e-02, 9.39083874e-01, 2.29251422e-02],\n",
       "       [4.69639013e-03, 9.10989702e-01, 8.43139812e-02],\n",
       "       [9.90883410e-01, 9.11658257e-03, 5.63273783e-09],\n",
       "       [6.77562226e-03, 7.51365781e-01, 2.41858691e-01],\n",
       "       [2.20596485e-06, 2.46979110e-02, 9.75299895e-01],\n",
       "       [1.04775892e-04, 1.58265367e-01, 8.41629863e-01],\n",
       "       [9.92652804e-06, 9.77164060e-02, 9.02273655e-01],\n",
       "       [2.11575578e-04, 2.63817579e-01, 7.35970914e-01],\n",
       "       [8.27142820e-02, 9.10621881e-01, 6.66385889e-03],\n",
       "       [9.80400562e-01, 1.95994750e-02, 4.02096383e-08],\n",
       "       [3.37620531e-06, 2.78134588e-02, 9.72183168e-01],\n",
       "       [1.24284759e-06, 2.74812821e-02, 9.72517490e-01],\n",
       "       [9.86277401e-01, 1.37225706e-02, 2.03093258e-08],\n",
       "       [5.50330104e-03, 8.80727708e-01, 1.13769002e-01],\n",
       "       [9.93294239e-01, 6.70574931e-03, 2.12783702e-09],\n",
       "       [2.44482234e-02, 9.42523062e-01, 3.30286734e-02],\n",
       "       [9.88332570e-01, 1.16673913e-02, 1.15249295e-08],\n",
       "       [9.92211342e-01, 7.78866466e-03, 3.72751874e-09],\n",
       "       [8.15211365e-07, 2.72454619e-02, 9.72753763e-01],\n",
       "       [9.85029280e-01, 1.49707152e-02, 2.79878503e-08],\n",
       "       [3.29513889e-04, 3.20186615e-01, 6.79483831e-01]], dtype=float32)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test=np.argmax(predicted,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, 1, 0, 1, 2, 2, 0, 1, 1, 2, 0, 1, 0, 0, 2, 2, 2, 0, 0, 0,\n",
       "       2, 0, 1, 1, 0, 1, 2, 2, 2, 2, 1, 0, 2, 2, 0, 1, 0, 1, 0, 0, 2, 0,\n",
       "       2], dtype=int64)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1_test=np.array(Y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_test=np.argmax(Y1_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, 1, 0, 1, 2, 2, 0, 1, 1, 1, 0, 1, 0, 0, 2, 2, 2, 0, 0, 0,\n",
       "       2, 0, 1, 1, 0, 1, 2, 2, 2, 2, 1, 0, 2, 2, 0, 1, 0, 1, 0, 0, 2, 0,\n",
       "       2], dtype=int64)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=accuracy_score(r_test,result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Linear+classification+using+Tensorflow+and+Keras.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
